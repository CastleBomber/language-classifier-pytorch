{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "print('PyTorch version', torch.__version__)\n",
        "print('Torchvision version', torchvision.__version__)"
      ],
      "metadata": {
        "id": "254WY9pJUvi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f263383-5ae4-4861-f8a1-bbfdf31b43ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version 2.4.1+cu121\n",
            "Torchvision version 0.19.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Colab Notebooks/language-classifier/language-datasets'\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Standard normalization\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = datasets.ImageFolder(os.path.join(base_path, 'train'), transform=transform)\n",
        "val_dataset = datasets.ImageFolder(os.path.join(base_path, 'val'), transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n"
      ],
      "metadata": {
        "id": "qV2Uts71MG49"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}